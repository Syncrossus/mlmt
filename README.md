## Pre-trained word embeddings

Pre-trained word embeddings for English, Dutch, Spanish, Russian, and Chechen can be found at [this page](http://www.limteng.com/research/2018/05/14/pretrained-word-embeddings.html).

## Reference

- Lin, Y., Yang, S., Stoyanov, V., Ji, H. (2018) *A Multi-lingual Multi-task Architecture for Low-resource Sequence Labeling*. Proceedings of The 56th Annual Meeting of the Association for Computational Linguistics. \[[pdf](http://nlp.cs.rpi.edu/paper/multilingualmultitask.pdf)\]

```
@inproceedings{ying2018multi,
    title     = {A Multi-lingual Multi-task Architecture for Low-resource Sequence Labeling},
    author    = {Ying Lin and Shengqi Yang and Veselin Stoyanov and Heng Ji},
    booktitle = {Proceedings of The 56th Annual Meeting of the Association for Computational Linguistics (ACL2018)},
    year      = {2018}
}
```
